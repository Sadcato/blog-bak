---
   title: è¯•ä¸€è¯•ç”¨æ‰‹åŠ¿å»æ§åˆ¶éŸ³é‡åˆå¦‚ä½•å‘¢
   date: YYYY-MM-DD HH:mm:ss
   tags:
     - è§†è§‰
   categories:
     - æŠ€æœ¯
   cover: img/opencv.jpg
---
## å‰è¨€
OpenCVç»ƒä¹ ï¼ŒæŠ€æœ¯æ°´å¹³ä¸åˆ°ä½ï¼Œè¿˜æœ›è¯»è€…å¤§ä½¬ä»¬æµ·æ¶µ
[ğŸ¦‰è¿™æ˜¯æºç ](https://github.com/Sadcato/Landslide-monitoring-and-early-warning-system-based-on-deep-learning)

## ä½¿ç”¨OpenCVå’ŒMediapipeå®ç°æ‰‹åŠ¿æ§åˆ¶ç”µè„‘éŸ³é‡
OpenCV: è´Ÿè´£è§†é¢‘æµçš„è¯»å–ã€å¤„ç†ä»¥åŠå¯è§†åŒ–æ‰‹åŠ¿è¯†åˆ«ç»“æœã€‚
Mediapipe: Google å¼€å‘çš„æœºå™¨å­¦ä¹ åº“ï¼Œæä¾›äº†é«˜æ•ˆçš„æ‰‹éƒ¨æ£€æµ‹å’Œå…³é”®ç‚¹è¯†åˆ«åŠŸèƒ½ã€‚
PyCaw: ç”¨äºæ§åˆ¶ç”µè„‘éŸ³é‡çš„Pythonåº“ï¼Œå¯ä»¥ç›´æ¥ä¿®æ”¹ç³»ç»ŸéŸ³é‡å¤§å°ã€‚

## å®ç°æ­¥éª¤

### ä¾èµ–åº“å¯¼å…¥
å¯¼å…¥æ‰€éœ€çš„Pythonåº“ã€‚OpenCV ç”¨äºè§†é¢‘å¤„ç†ï¼ŒMediapipe ç”¨äºæ‰‹éƒ¨æ£€æµ‹ï¼ŒPyCaw ç”¨äºéŸ³é‡æ§åˆ¶ã€‚æ­¤å¤–ï¼Œmath å’Œ numpy ç”¨äºè®¡ç®—æ‰‹æŒ‡é—´çš„è·ç¦»åŠå…¶ä¸éŸ³é‡çš„æ˜ å°„ã€‚
``` Python
import cv2
import mediapipe as mp
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
import time
import math
import numpy as np

```

### åˆå§‹åŒ–
åˆå§‹åŒ– Mediapipe çš„ Hands æ¨¡å—
``` Python
class HandControlVolume:
    def __init__(self):
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_hands = mp.solutions.hands

        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(
            IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        self.volume = cast(interface, POINTER(IAudioEndpointVolume))
        self.volume.SetMute(0, None)
        self.volume_range = self.volume.GetVolumeRange()

```
### æ‘„åƒå¤´è¾“å…¥ä¸æ‰‹åŠ¿æ£€æµ‹
ä½¿ç”¨ OpenCV æ‰“å¼€æ‘„åƒå¤´ï¼Œå¹¶å®æ—¶æ•æ‰è§†é¢‘å¸§ã€‚é€šè¿‡ Mediapipe æ£€æµ‹æ‰‹éƒ¨å…³é”®ç‚¹ï¼Œè¯†åˆ«å¤§æ‹‡æŒ‡å’Œé£ŸæŒ‡çš„ä½ç½®ã€‚
``` Python
cap = cv2.VideoCapture(0)
resize_w = 640
resize_h = 480

with self.mp_hands.Hands(min_detection_confidence=0.7,
                         min_tracking_confidence=0.5,
                         max_num_hands=2) as hands:
    while cap.isOpened():
        success, image = cap.read()
        image = cv2.resize(image, (resize_w, resize_h))

        # å›¾åƒç¿»è½¬å’Œå¤„ç†
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.flip(image, 1)
        results = hands.process(image)

        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

```

### è®¡ç®—æ‰‹æŒ‡è·ç¦»å¹¶æ˜ å°„ä¸ºéŸ³é‡
æ£€æµ‹åˆ°æ‰‹æŒåï¼Œç³»ç»Ÿä¼šè¯†åˆ«å‡ºå¤§æ‹‡æŒ‡å’Œé£ŸæŒ‡çš„åæ ‡ï¼Œé€šè¿‡å‹¾è‚¡å®šç†è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»ã€‚æ ¹æ®è·ç¦»å¤§å°ï¼Œä½¿ç”¨ numpy.interp() å‡½æ•°å°†å…¶æ˜ å°„åˆ°éŸ³é‡å€¼çš„èŒƒå›´ï¼ˆä»æœ€å°åˆ°æœ€å¤§éŸ³é‡ï¼‰ã€‚

ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·ç†è§£ï¼Œç¨‹åºè¿˜åœ¨è§†é¢‘æµä¸­ç»˜åˆ¶æ‰‹æŒ‡çš„å…³é”®ç‚¹åŠè¿æ¥çº¿ï¼ŒåŒæ—¶åœ¨å±å¹•ä¸Šä»¥ç™¾åˆ†æ¯”å½¢å¼æ˜¾ç¤ºå½“å‰éŸ³é‡ã€‚
```Python
image = cv2.circle(image, (thumb_finger_tip_x, thumb_finger_tip_y), 10, (255, 0, 255), -1)
image = cv2.line(image, (thumb_finger_tip_x, thumb_finger_tip_y),
                 (index_finger_tip_x, index_finger_tip_y), (255, 0, 255), 5)

# æ˜¾ç¤ºéŸ³é‡ç™¾åˆ†æ¯”
cv2.putText(image, str(math.ceil(rect_percent_text)) + "%", (10, 350),
            cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)

```